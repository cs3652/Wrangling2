---
title: "Wrangling2part1"
author: "Chirag Shah"
date: '2018-10-11'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(rvest)
library(httr)
```

Read in data

```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"
drug_use_xml = read_html(url)

drug_use_xml
```

Doesn’t look like much, but we’re there. Rather than trying to grab something using a CSS selector, let’s try our luck extracting the tables from the HTML.
Try to pull out any html table that is labelled "table"
```{r}
drug_use_xml %>%
  html_nodes(css = "table")
```

This has extracted all of the tables on the original page; that’s why we have a list with 15 elements. (We haven’t really talked about lists yet, but for now you can think of them as a general collection of objects in R. As we proceed, syntax for extracting individual elements from a list will become clear, and we’ll talk lots about lists in list columns.)

We’re only focused on the first table for now, so let’s get the contents from the first list element.

```{r}
table_marj = (drug_use_xml %>% html_nodes(css = "table"))[[1]] %>%
  html_table() 
```
there is also html_text() etc to extract other information 

I won’t print the table here, but if you look at it you’ll notice a problem: the “note” at the bottom of the table appears in every column in the first row. We need to remove that; I’ll also convert to a tibble so that things print nicely.

```{r}
table_marj = (drug_use_xml %>% html_nodes(css = "table"))[[1]] %>%
  html_table() %>%
  .[-1,] %>% 
  as_tibble()

table_marj
```

We have the data in R but we cannot really use it because not tidy and there are character variables etc. 

```{r}
url = "https://www.bestplaces.net/cost_of_living/city/new_york/new_york"
nyc_cost = read_html(url)

nyc_cost
```

Learning assessment

```{r}
table_nyc = (nyc_cost %>% html_nodes(css = "table"))[[1]] %>%
  html_table() %>%
  .[-1,] %>% 
  as_tibble()

table_nyc
```

```{r}
nyc_cost = read_html("https://www.bestplaces.net/cost_of_living/city/new_york/new_york") %>%
  html_nodes(css = "table") %>%
  .[[1]] %>%
  html_table(header = TRUE)
```

##CSS Selectors

```{r}
hpsaga_html = read_html("https://www.imdb.com/list/ls000630791/")
```

For each element, I’ll use the CSS selector (selector gadget, chrome extention) in html_nodes() to extract the relevant HTML code, and convert it to text. Then I can combine these into a data frame.

```{r}
title_vec = hpsaga_html %>%
  html_nodes(".lister-item-header a") %>%
  html_text()

gross_rev_vec = hpsaga_html %>%
  html_nodes(".text-small:nth-child(7) span:nth-child(5)") %>% ##getting money made from each film
  html_text()

runtime_vec = hpsaga_html %>%
  html_nodes(".runtime") %>%
  html_text()

hpsaga_df = tibble(
  title = title_vec,
  rev = gross_rev_vec,
  runtime = runtime_vec
)
```

learning assessment 
```{r}
url = "https://www.amazon.com/product-reviews/B00005JNBQ/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1"

dynamite_html = read_html(url)

review_titles = dynamite_html %>%
  html_nodes("#cm_cr-review_list .review-title") %>%
  html_text()

review_stars = dynamite_html %>%
  html_nodes("#cm_cr-review_list .review-rating") %>%
  html_text()

review_text = dynamite_html %>%
    html_nodes(".review-data:nth-child(4)") %>%
    html_text()

reviews = tibble(
  title = review_titles,
  stars = review_stars,
  text = review_text
)
```

##Using an API
As a simple example, this page is about a dataset for annual water consumption in NYC, along with the population in that year. First, we’ll import this as a CSV and parse it.
Click API on the webpage and you can ask for a csv page or a JSON 
```{r}
nyc_water = GET("https://data.cityofnewyork.us/resource/waf7-5gvc.csv") %>% 
  content("parsed")
```
We can also import this dataset as a JSON file. This takes a bit more work (and this is, really, a pretty easy case), but it’s still doable.
```{r}
nyc_water = GET("https://data.cityofnewyork.us/resource/waf7-5gvc.json") %>% 
  content("text") %>%
  jsonlite::fromJSON() %>%
  as_tibble()
```
Data.gov also has a lot of data available using their API; often this is available as CSV or JSON as well. For example, we might be interested in data coming from BRFSS. This is importable via the API as a CSV (JSON, in this example, is much more complicated).
```{r}
brfss_smart2010 = 
  GET("https://data.cdc.gov/api/views/acme-vg9e/rows.csv?accessType=DOWNLOAD") %>% 
  content("parsed")
```
Both of the previous examples are extremely easy – we accessed data that is essentially a data table, and we had a very straightforward API.

To get a sense of how this becomes complicated, let’s look at the Pokemon API (which is also pretty nice).
```{r}
poke = GET("http://pokeapi.co/api/v2/pokemon/1") %>%
  content()

poke$name

poke$height

poke$abilities
```


